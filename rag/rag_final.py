import streamlit as st
import pandas as pd
import os
import time
import re
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.documents import Document
from rank_bm25 import BM25Okapi

# ---------------------------------------------------------
# 1. í™˜ê²½ ì„¤ì • ë° API ë¡œë“œ (ë¬´ì†ì‹¤ ë³´ì¡´)
# ---------------------------------------------------------
current_dir = os.path.dirname(os.path.abspath(__file__))
env_path = os.path.join(current_dir, '.env')
load_dotenv(dotenv_path=env_path)

# ---------------------------------------------------------
# 2. í”„ë¦¬ë¯¸ì—„ ë””ìì¸ ë¦¬ë‰´ì–¼ (Daiso Red & Pink Review Box)
# ---------------------------------------------------------
st.set_page_config(page_title="ë‹¤ì´ì†Œ ë·°í‹° íë ˆì´í„° v62", layout="wide")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@300;400;600;800&display=swap');
    * { font-family: 'Pretendard', sans-serif; }

    .stApp { background-color: #FFFFFF; }
    
    /* ìƒë‹¨ ë°°ë„ˆ - ë‹¤ì´ì†Œ ë ˆë“œ í”„ë¦¬ë¯¸ì—„ ê·¸ë¼ë°ì´ì…˜ */
    .welcome-banner {
        background: linear-gradient(135deg, #FF1535 0%, #D60E2A 100%);
        padding: 60px 20px; border-radius: 30px; color: white; text-align: center;
        margin-bottom: 40px; box-shadow: 0 20px 40px rgba(255, 21, 53, 0.15);
    }
    .welcome-banner h1 { margin: 0; font-size: 3.5rem; font-weight: 800; letter-spacing: -2px; }
    .welcome-banner p { margin: 20px 0 0; font-size: 1.2rem; font-weight: 300; opacity: 0.9; }

    /* ì „ë¬¸ê°€ í”„ë¡œí•„ - ì‹ ë¢°ë„ ë†’ì€ ìŠ¤íƒ€ì¼ */
    .expert-intro {
        display: flex; align-items: center; gap: 25px; background: #F8F9FA;
        padding: 35px; border-radius: 25px; border-left: 12px solid #FF1535;
        margin-bottom: 40px; box-shadow: 0 10px 20px rgba(0,0,0,0.03);
    }
    .expert-avatar {
        font-size: 55px; background: #FFFFFF; width: 95px; height: 95px;
        display: flex; align-items: center; justify-content: center;
        border-radius: 50%; box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    .expert-text { font-size: 1.2rem; color: #333; line-height: 1.7; font-weight: 500; }
    .expert-text b { color: #FF1535; font-weight: 700; }

    /* ì±„íŒ… ë©”ì‹œì§€ ì¹´ë“œ ë””ìì¸ */
    [data-testid="stChatMessage"] {
        background-color: #fcfcfc; border: 1px solid #f0f0f0;
        border-radius: 25px; padding: 30px; margin-bottom: 25px;
        box-shadow: 0 5px 15px rgba(0,0,0,0.02);
    }

    /* [v62.0 í•µì‹¬] ë² ìŠ¤íŠ¸ ë¦¬ë·° ìš”ì•½ í•‘í¬ ë°•ìŠ¤ */
    .review-box {
        background-color: #FFF0F3; 
        border: 2px solid #FFD1DC; 
        border-radius: 20px; 
        padding: 25px;
        margin-top: 30px;
        margin-bottom: 20px;
        box-shadow: 0 8px 20px rgba(255, 21, 53, 0.05);
    }
    .review-title {
        font-weight: 800; color: #FF1535; font-size: 1.2rem;
        margin-bottom: 12px; display: flex; align-items: center; gap: 10px;
    }
    .review-content { color: #555; font-size: 1.1rem; line-height: 1.6; font-style: italic; }

    /* êµ¬ë§¤ ë§í¬ ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .buy-link {
        display: inline-block; padding: 15px 35px; background-color: #FF1535;
        color: white !important; text-decoration: none !important;
        border-radius: 50px; font-weight: 600; margin-top: 15px;
        box-shadow: 0 10px 20px rgba(255, 21, 53, 0.2);
        transition: all 0.3s ease;
    }
    .buy-link:hover { transform: translateY(-3px); box-shadow: 0 15px 25px rgba(255, 21, 53, 0.3); }

    /* ì‚¬ì´ë“œë°” ë””ìì¸ */
    [data-testid="stSidebar"] { background-color: #FFFFFF; border-right: 1px solid #eee; }
    .sidebar-title { color: #FF1535; font-weight: 800; font-size: 1.6rem; margin-bottom: 20px; text-align: center; }
    </style>
    """, unsafe_allow_html=True)

# ---------------------------------------------------------
# 3. ë°ì´í„° ë¡œë“œ ë° ë²¡í„° ì €ì¥ì†Œ ([DIYíŒ¨ë“œ ì˜êµ¬ ì‚­ì œ] ë¬´ì†ì‹¤)
# ---------------------------------------------------------
@st.cache_resource
def get_vectorstore():
    persist_directory = os.path.join(current_dir, "chroma_db_v62")
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    csv_file = os.path.join(current_dir, "final_integrated_data_v2.csv")
    
    if not os.path.exists(csv_file):
        st.error("ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."); st.stop()
    
    df = pd.read_csv(csv_file, encoding="utf-8-sig")
    # [í•µì‹¬] ê·œë¹ˆë‹˜ì´ ì§€ì í•˜ì‹  ì´ìƒì¹˜ DIYíŒ¨ë“œ ë°ì´í„° ì˜êµ¬ ì‚­ì œ
    df = df[~df['ìƒí’ˆëª…'].str.contains('DIYíŒ¨ë“œ|diyíŒ¨ë“œ|DIY íŒ¨ë“œ', na=False, case=False)]
    
    documents = []
    for _, row in df.iterrows():
        content = "\n".join([f"{col}: {row[col]}" for col in df.columns if pd.notna(row[col])])
        documents.append(Document(
            page_content=content, 
            metadata={
                "ìƒí’ˆëª…": str(row.get('ìƒí’ˆëª…', '')),
                "review_count": int(row.get('ë¦¬ë·°ìˆ˜', 0)), 
                "rating": row.get('í‰ì ', 0),
                "detail": str(row.get('ìƒì„¸ì •ë³´', '')),
                "summary": str(row.get('í•œì¤„ìš”ì•½', ''))
            }
        ))
    return Chroma.from_documents(documents=documents, embedding=embeddings, persist_directory=persist_directory)

vectorstore = get_vectorstore()

# ---------------------------------------------------------
# 4-1. BM25 ì¸ë±ìŠ¤ ìƒì„± (ë¬´ì†ì‹¤ ë³´ì¡´)
# ---------------------------------------------------------
def simple_tokenizer(text):
    if not isinstance(text, str): return []
    return re.findall(r'[ê°€-í£a-zA-Z0-9]{1,}', re.sub(r'[_\-().]', ' ', text))

@st.cache_resource
def get_bm25_index():
    df = pd.read_csv(os.path.join(current_dir, "final_integrated_data_v2.csv"), encoding="utf-8-sig")
    df = df[~df['ìƒí’ˆëª…'].str.contains('DIYíŒ¨ë“œ|diyíŒ¨ë“œ', na=False, case=False)]
    doc_texts = [" ".join([str(row[c]) for c in ['ìƒí’ˆëª…', 'ìƒì„¸ì •ë³´', 'í•œì¤„ìš”ì•½'] if c in df.columns]) for _, row in df.iterrows()]
    return BM25Okapi([simple_tokenizer(d) for d in doc_texts]), doc_texts

bm25_index, bm25_documents = get_bm25_index()

# ---------------------------------------------------------
# 4-2. ìµœê°• í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ë­í‚¹ ê²€ìƒ‰ (v52.0 ë¡œì§ ì™„ì „ ì‚¬ìˆ˜)
# ---------------------------------------------------------
def get_advanced_context(query, k=60):
    query_clean = query.lower()
    v_docs = vectorstore.similarity_search(query_clean, k=k)
    
    doc_scores = {}
    for rank, doc in enumerate(v_docs):
        doc_scores[doc.page_content] = {'vector': 1.0 - (rank * 0.015), 'bm25': 0, 'doc': doc}
    
    if bm25_index:
        bm25_scs = bm25_index.get_scores(simple_tokenizer(query_clean))
        top_indices = sorted(range(len(bm25_scs)), key=lambda i: bm25_scs[i], reverse=True)[:k]
        max_v = max(bm25_scs) if max(bm25_scs) > 0 else 1
        for i in top_indices:
            text = bm25_documents[i]
            if text in doc_scores: doc_scores[text]['bm25'] = bm25_scs[i] / max_v
            else: doc_scores[text] = {'vector': 0, 'bm25': bm25_scs[i] / max_v, 'doc': Document(page_content=text)}

    # í‚¤ì›Œë“œ ì‚¬ì „
    category_keywords = {
        "í† ë„ˆ": ["í† ë„ˆ", "ìŠ¤í‚¨", "ë¯¸ìŠ¤íŠ¸", "íŒ¨ë“œ", "í† ë„ˆíŒ¨ë“œ"],
        "í¬ë¦¼": ["í¬ë¦¼", "ìˆ˜ë”©í¬ë¦¼", "ì ¤í¬ë¦¼", "ë³´ìŠµí¬ë¦¼", "ì˜ì–‘í¬ë¦¼", "ë©€í‹°ë°¤", "ìŠ¤í‹±"],
        "ì•°í”Œ": ["ì•°í”Œ", "ì„¸ëŸ¼", "ì—ì„¼ìŠ¤", "ì˜¤ì¼ì•°í”Œ", "ì˜ì–‘ì•°í”Œ"]
    }
    effect_keywords = {
        "ì§„ì •": ["ì§„ì •", "ì‹œì¹´", "ì–´ì„±ì´ˆ", "ìˆ˜ë”©", "íŒí…Œë†€"],
        "ë¯¸ë°±": ["ë¯¸ë°±", "ë¹„íƒ€", "ê´‘ì±„", "ë¸Œë¼ì´íŠ¸ë‹", "ì¡í‹°"],
        "ì˜¤ì¼/ê³ ë³´ìŠµ": ["ì˜¤ì¼", "ì˜ì–‘", "ê³ ë³´ìŠµ", "ì„¸ë¼ë§ˆì´ë“œ", "ë°¤", "ìŠ¤í‹±", "ê¾¸ë•", "ì‹¬í•œ ê±´ì„±"]
    }

    target_cats = [k for k, v in category_keywords.items() if any(kw in query_clean for kw in v + [k])]
    target_effs = [k for k, v in effect_keywords.items() if any(kw in query_clean for kw in v + [k])]

    final_scored = []
    for text, sc in doc_scores.items():
        hybrid_score = (sc['vector'] * 0.7) + (sc['bm25'] * 0.3)
        prod_name = sc['doc'].metadata.get('ìƒí’ˆëª…', '').lower()
        detail_text = sc['doc'].metadata.get('detail', '').lower()
        
        # 1. [ê³„ì¸µ 1] ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ (+500,000ì ) - ìµœìš°ì„  ìˆœìœ„
        if any(any(kw in prod_name for kw in category_keywords[cat]) for cat in target_cats):
            hybrid_score += 500000.0
        
        # 2. [ê³„ì¸µ 2] íš¨ê³¼/ì œí˜• ì •ë°€ ë§¤ì¹­ (+100,000ì )
        if any(any(kw in prod_name or kw in detail_text for kw in effect_keywords[eff]) for eff in target_effs):
            hybrid_score += 100000.0

        # 3. [ê³„ì¸µ 3] ë¦¬ë“¤ìƒ· ë°©ì–´ í˜ë„í‹° ë¡œì§ (v52.0 í•µì‹¬ ë¬´ì†ì‹¤)
        if any(kw in query_clean for kw in ["ì˜¤ì¼", "ì˜ì–‘", "ì§„ì • í† ë„ˆ"]):
            if any(kw in prod_name for kw in ["ë¦¬ë“¤ìƒ·", "ë¶€ìŠ¤íŒ…", "ë¶€ìŠ¤í„°"]):
                hybrid_score -= 800000.0
        
        # 4. [ê³„ì¸µ 4] ì¸ê¸°ìˆœ ê°€ì¤‘ì¹˜
        review_count = sc['doc'].metadata.get('review_count', 0)
        hybrid_score += (review_count / 10) 
        
        final_scored.append((review_count, hybrid_score, sc['doc']))

    final_scored.sort(key=lambda x: (x[1], x[0]), reverse=True)
    return final_scored[:3] # ìƒìœ„ 3ê°œ ì œí’ˆë§Œ ê²°ê³¼ë¡œ ìƒì„±

# ---------------------------------------------------------
# 5. [ë§ˆìŠ¤í„° í”„ë¡¬í”„íŠ¸] ê°€ë…ì„± & í˜•ì‹ & ì´ëª¨í‹°ì½˜ ì™„ë²½ ì œì–´
# ---------------------------------------------------------
system_prompt = """ê·€í•˜ëŠ” ë‹¤ì´ì†Œì˜ ì „ë¬¸ ë·°í‹° íë ˆì´í„° 'ë·°í‹° ë²„ë””'ì…ë‹ˆë‹¤. 

[ğŸ” ê·œë¹ˆë‹˜ ìš”ì²­ ë‹µë³€ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ - v62.0]
1. **6ë‹¨ê³„ ê³ ì • í¬ë§·**: ë°˜ë“œì‹œ ì•„ë˜ì˜ ë¼ë²¨ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì‹­ì‹œì˜¤.
   - ğŸ§´ **í”¼ë¶€ íƒ€ì…**: ì‚¬ìš©ìì˜ ê³ ë¯¼ì„ ë¶„ì„í•˜ê³  ì œí’ˆì˜ ì í•©ì„±ì„ ìƒì„¸íˆ ì„¤ëª….
   - ğŸ·ï¸ **ì¹´í…Œê³ ë¦¬**: ìš”ì²­í•œ ì¹´í…Œê³ ë¦¬ì™€ì˜ ì¼ì¹˜ì„± í™•ì¸.
   - ğŸ”¥ **ì¸ê¸°ìˆœ**: ì‹¤ì œ ë¦¬ë·° ìˆ˜ì™€ í‰ì  ì–¸ê¸‰.
   - ğŸ§ª **ì„±ë¶„ ë° íš¨ê³¼**: [í•µì‹¬ ì„±ë¶„], [ì‘ìš© ì›ë¦¬], [ê³ ë¯¼ í•´ê²°]ë¡œ êµ¬ë¶„.
   - #REVIEW#: ë³¸ë¬¸ì—ëŠ” ë¦¬ë·° ë¼ë²¨ì„ ì“°ì§€ ë§ê³  ì´ êµ¬ë¶„ì ë’¤ì— ë¦¬ë·° ë‚´ìš©ë§Œ ì‘ì„±.
   - ğŸ”— **ë§í¬**: êµ¬ë§¤ URL ëª…ì‹œ.

2. **ì„±ë¶„ ì„¹ì…˜ ê°€ë…ì„±**: 
   - [í•µì‹¬ ì„±ë¶„], [ì‘ìš© ì›ë¦¬], [ê³ ë¯¼ í•´ê²°] ì‚¬ì´ì—ëŠ” ë°˜ë“œì‹œ **ì¤„ë°”ê¿ˆ(ì—”í„°) ë‘ ë²ˆ**ì„ ë„£ì–´ ê°€ë…ì„±ì„ í™•ë³´í•˜ì‹­ì‹œì˜¤.
   - ë°ì´í„°ì— í•µì‹¬ ì„±ë¶„ì´ ì—†ìœ¼ë©´ [í•µì‹¬ ì„±ë¶„] íƒ€ì´í‹€ê³¼ ë‚´ìš©ì„ ì•„ì˜ˆ ìƒëµí•˜ì‹­ì‹œì˜¤.

3. **ê¸°í˜¸ ì‚¬ìš© ê¸ˆì§€**: ë™ê·¸ë¼ë¯¸(â—‹, â—, â€¢), ë³„í‘œ, ë¹ˆ ê´„í˜¸([]) ë“±ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

4. **ì „ë¬¸ì„± ìœ ì§€**: ê·œë¹ˆë‹˜ì´ ì¢‹ì•„í•˜ì‹  "ì§€ì„± í”¼ë¶€ëŠ” í”¼ì§€ ë¶„ë¹„ê°€ ë§ì•„..." ì‹ì˜ ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ìœ ì§€í•˜ì‹­ì‹œì˜¤.

ì§ˆë¬¸: {question}
ì°¸ì¡° ë¬¸ì„œ: {context}
ë‹µë³€:"""

prompt = PromptTemplate.from_template(system_prompt)
llm = ChatOpenAI(model_name="gpt-4o", temperature=0, streaming=True)

# ---------------------------------------------------------
# 6. UI ë Œë”ë§ ë° ì‚¬ì´ë“œë°”
# ---------------------------------------------------------
st.sidebar.markdown("<div class='sidebar-title'>ğŸ’„ DAISO BEAUTY</div>", unsafe_allow_html=True)
st.sidebar.markdown("---")
st.sidebar.write("âœ… **v62.0 ë§ˆìŠ¤í„° ë²„ì „**")
st.sidebar.write("- ë¦¬ë“¤ìƒ· í˜ë„í‹° ë¡œì§ íƒ‘ì¬")
st.sidebar.write("- ì¹´í…Œê³ ë¦¬ 50ë§Œì  ê°€ì¤‘ì¹˜")
st.sidebar.write("- ë² ìŠ¤íŠ¸ ë¦¬ë·° í•‘í¬ ë°•ìŠ¤")
st.sidebar.markdown("---")

st.markdown("""
    <div class='welcome-banner'>
        <h1>DAISO BEAUTY CURATION</h1>
        <p>ë‹¹ì‹ ë§Œì„ ìœ„í•œ ë‹¤ì´ì†Œ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì •ë°€ íë ˆì´ì…˜</p>
    </div>
    <div class='expert-intro'>
        <div class='expert-avatar'>ğŸ’„</div>
        <div class='expert-text'>
            ì•ˆë…•í•˜ì„¸ìš”, ê³ ê°ë‹˜! <b>ë‹¤ì´ì†Œ ì „ë¬¸ íë ˆì´í„°</b>ì…ë‹ˆë‹¤.<br>
            ê³ ê°ë‹˜ì˜ í”¼ë¶€ ê³ ë¯¼ì„ í•´ê²°í•  <b>ìµœì ì˜ ì„±ë¶„ê³¼ ì••ë„ì  ì¸ê¸°</b>ë¥¼ ê°€ì§„ ì œí’ˆì„ ì°¾ì•„ë“œë¦´ê²Œìš”.
        </div>
    </div>
    """, unsafe_allow_html=True)

if "messages" not in st.session_state: st.session_state.messages = []
for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"], unsafe_allow_html=True)

# ---------------------------------------------------------
# 7. ì‹¤í–‰ ë¡œì§ (ìŠ¤íŠ¸ë¦¬ë° & ë¦¬ë·° ë°•ìŠ¤ ë¶„ë¦¬ - ë¬´ì†ì‹¤)
# ---------------------------------------------------------
user_input = st.chat_input("í”¼ë¶€íƒ€ì…ê³¼ ê³ ë¯¼ì„ ì…ë ¥í•˜ì„¸ìš”... (ì˜ˆ: ê±´ì„±ì¸ë° ì˜¤ì¼ ì•°í”Œ ì¶”ì²œ)")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"): st.markdown(f"<b>{user_input}</b>", unsafe_allow_html=True)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        with st.spinner("ë‹¤ì´ì†Œì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ì •ë°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            top_results = get_advanced_context(user_input)
            context = "\n\n".join([d[2].page_content for d in top_results])
            
            chain = ({"context": lambda x: context, "question": RunnablePassthrough()} | prompt | llm | StrOutputParser())
            
            for chunk in chain.stream(user_input):
                full_response += chunk
                display_text = full_response.split("#REVIEW#")[0]
                message_placeholder.markdown(display_text + "â–Œ", unsafe_allow_html=True)
            
            # ìµœì¢… ë Œë”ë§
            if "#REVIEW#" in full_response:
                main_content, review_part = full_response.split("#REVIEW#")
                message_placeholder.markdown(main_content, unsafe_allow_html=True)
                
                # [v62.0 í•µì‹¬] ë² ìŠ¤íŠ¸ ë¦¬ë·° ìš”ì•½ í•‘í¬ ë°•ìŠ¤ ë™ì  ì¶œë ¥
                st.markdown(f"""
                    <div class='review-box'>
                        <div class='review-title'>ğŸ’¬ ë² ìŠ¤íŠ¸ ë¦¬ë·° ìš”ì•½</div>
                        <div class='review-content'>"{review_part.strip()}"</div>
                    </div>
                    """, unsafe_allow_html=True)
            else:
                message_placeholder.markdown(full_response, unsafe_allow_html=True)
                
    st.session_state.messages.append({"role": "assistant", "content": full_response})