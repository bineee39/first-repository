# 회고
### 총평 및 학습 포인트

- 데이터의 중요성: 303개라는 적은 수의 데이터만으로는 아무리 다양한 기법을 적용하더라도 모델의 일반화 성능을 크게 향상시키기 어렵다는 것을 확인했습니다. 

- 데이터 증강을 통해 인위적으로 데이터 다양성을 늘렸음에도 불구하고, 실제 새로운 데이터에 대한 성능은 오히려 감소했습니다. 이는 데이터의 양과 질이 모델 성능에 가장 근본적인 영향을 미친다는 것을 보여줍니다.

- 과적합의 어려움: 훈련 데이터셋에 대한 높은 정확도(90% 이상)와 새로운 테스트 데이터셋에 대한 낮은 정확도(30%대)는 모델이 훈련 데이터에 과적합되었음을 알 수 있었습니다.

- Dropout, BatchNormalization, GlobalAveragePooling2D, 데이터 증강 등 다양한 정규화 및 일반화 기법을 시도했지만, 근본적인 데이터 부족 문제를 해결하기에는 역부족이었습니다.

- 테스트 데이터셋의 역할: data.zip과 scissor2/rock2/paper2.zip이라는 두 가지 테스트 데이터셋을 사용한 결과가 크게 달라, 테스트 데이터셋의 선택과 분포가 모델 평가에 얼마나 중요한지 깨달았습니다. 

  ### 향후 개선 방향:
  
- 데이터 확보: 데이터를 충분히 많이 확보하여 train 시키면 성능이 더 향상될 것을 기대해봅니다.
  
- 하이퍼파라미터 튜닝: 현재 설정된 하이퍼파라미터(학습률, 배치 크기, 에포크 등)를 보다 체계적으로 탐색하는 것이 필요합니다.
  
- 모델 구조 탐색: 현재보다 더 깊거나 넓은 네트워크, 혹은 다른 형태의 CNN 아키텍처를 탐색할 수 있습니다.
  
이번 프로젝트를 통해 딥러닝 모델의 성능을 향상시키기 위한 다양한 기법들을 적용해보고, 그 효과와 한계를 직접 경험하며 많은 것을 배울 수 있었습니다. 특히 데이터의 중요성을 다시 한번 강조하게 되는 과정이었습니다.
